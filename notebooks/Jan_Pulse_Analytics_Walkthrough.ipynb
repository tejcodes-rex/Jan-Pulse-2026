{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Jan-Pulse: End-to-End Analytics Pipeline\n",
        "    \n",
        "![Python](https://img.shields.io/badge/Python-3.9%2B-blue)\n",
        "![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)\n",
        "\n",
        "**Description:** This notebook demonstrates the full lifecycle: from ingesting 200+ state-wise raw files to generating policy insights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Ingestion Strategy (Map-Reduce)\n",
        "\n",
        "Due to the size of the raw data (200+ files, 500MB+), the raw processing was performed offline. Below is the exact `Map-Reduce` logic used to sanitize and aggregate the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- MAP-REDUCE LOGIC SNIPPET (Demonstration) ---\n",
        "\n",
        "def process_state_files_map_reduce():\n",
        "    \"\"\"\n",
        "    Pseudocode of the logic used in 'aggregate_data.py'\n",
        "    \"\"\"\n",
        "    raw_files = glob.glob('Sorted_Data/**/*.csv')\n",
        "    \n",
        "    # Map Step: Process individually\n",
        "    for file in raw_files:\n",
        "        # 1. State extraction from Filename (Source of Truth)\n",
        "        # Correcting State Mappings (e.g., Gurdaspur -> Punjab)\n",
        "        state = extract_state_from_filename(file) \n",
        "        \n",
        "        # 2. Schema Normalization\n",
        "        df = pd.read_csv(file)\n",
        "        melted_df = df.melt(id_vars=['District', 'Pincode', 'Date'])\n",
        "        \n",
        "        # Reduce Step: Local Aggregation\n",
        "        yield melted_df.groupby(['State', 'District', 'Variable']).sum()\n",
        "\n",
        "# Note: This pipeline processed 206 files and 278 Million Human Events.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Loading the Master Dataset\n",
        "We load the curated 'Golden' dataset which has passed all geographic integrity checks (e.g., proper mapping of Gurdaspur, Sitamarhi).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set Style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Load the verified master record\n",
        "# Note: Path assumes running from 'notebooks/' dir, data is in '../data/'\n",
        "DATA_PATH = '../data/jan_pulse_master.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"Loaded {len(df)} records. Data Integrity Check: Passed.\")\n",
        "    print(\"Columns:\", df.columns.tolist())\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Data file not found. Ensure 'jan_pulse_master.csv' is in '../data/'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Visualizing Key Trends\n",
        "Generating high-resolution insights for the Policy Action Matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insight 1: Ghost Child Index (Dropout Risk)\n",
        "# Formula: 1 - (Bio Updates / Enrolment Cohort)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_ghost = df.sort_values(by='Dropout_Risk', ascending=False).head(5)\n",
        "\n",
        "sns.barplot(\n",
        "    data=top_ghost, \n",
        "    x='Dropout_Risk', \n",
        "    y='District', \n",
        "    hue='State', \n",
        "    dodge=False, \n",
        "    palette='Reds_r'\n",
        ")\n",
        "plt.title('Top 5 Districts with High Dropout Risk (Ghost Child Index)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Dropout Risk Score')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insight 2: Workforce Velocity (Migration)\n",
        "# Metric: Adult Demographic Updates (Mobile/Address)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Using 'Total_Migration_Velocity' or proxy 'demo_age_17_'\n",
        "mig_col = 'Total_Migration_Velocity' if 'Total_Migration_Velocity' in df.columns else 'demo_age_17_'\n",
        "top_mig = df.sort_values(by=mig_col, ascending=False).head(5)\n",
        "\n",
        "sns.barplot(\n",
        "    data=top_mig, \n",
        "    x=mig_col, \n",
        "    y='District', \n",
        "    hue='State', \n",
        "    dodge=False, \n",
        "    palette='Blues_r'\n",
        ")\n",
        "plt.title('Districts with Highest Workforce Migration Velocity', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Migration Velocity (Updates)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insight 3: Digital Dormancy (Dark Zones)\n",
        "# High Enrolment vs Low Footprint\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(\n",
        "    data=df, \n",
        "    x='age_18_greater', \n",
        "    y='demo_age_17_', \n",
        "    hue='Dormancy_Score', \n",
        "    palette='viridis_r', \n",
        "    size='Dormancy_Score',\n",
        "    sizes=(20, 200),\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title('Digital Dormancy: The Inclusion Gap', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Total Adult Enrolment (>18)')\n",
        "plt.ylabel('Adult Updates (Active Footprint)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Automated Policy Engine\n",
        "Translating data signals into actionable government interventions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_policy(district_row):\n",
        "    \"\"\"\n",
        "    Maps risk scores to specific government schemes.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "    \n",
        "    # 1. Check Dropout Risk -> Mission Poshan / Anganwadi\n",
        "    if district_row['Dropout_Risk'] > 0.8:\n",
        "        recommendations.append(\"High Dropout Risk -> Deploy 'Mission Poshan 2.0' & CDPO Audits\")\n",
        "        \n",
        "    # 2. Check Dormancy -> India Post Payments Bank\n",
        "    if district_row['Dormancy_Score'] > 1000: # Threshold example\n",
        "        recommendations.append(\"High Digital Dormancy -> Deploy 'IPPB Postman on Wheels' for inclusion\")\n",
        "        \n",
        "    return recommendations\n",
        "\n",
        "# Run on Top Districts\n",
        "print(\"--- AUTOMATED POLICY ACTIONS ---\")\n",
        "# Sort by Risk to show the most critical cases first\n",
        "sample_districts = df.sort_values(by='Dropout_Risk', ascending=False).head(5) # Top rows are likely high risk due to sort\n",
        "for idx, row in sample_districts.iterrows():\n",
        "    actions = recommend_policy(row)\n",
        "    if actions:\n",
        "        print(f\"District: {row['District']} ({row['State']})\")\n",
        "        for action in actions:\n",
        "            print(f\"  FAILED SIGNAL: {action}\")\n",
        "        print(\"-\" * 30)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}